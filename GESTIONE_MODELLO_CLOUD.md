# üß† Gestione Modello SBERT su Streamlit Cloud

## ‚ùì Il Problema

Streamlit Cloud ha **storage effimero**:
- Il filesystem viene resettato ad ogni riavvio del container
- Modelli scaricati vanno persi
- Il modello SBERT (~60-90MB) verrebbe scaricato ogni volta

**Quando avviene un riavvio?**
- Aggiornamenti del codice (push su GitHub)
- Riavvio automatico di Streamlit Cloud
- Inattivit√† prolungata (>7 giorni senza visitatori)

---

## ‚úÖ Soluzione Implementata (Ibrida)

L'app ora supporta **due modalit√†**:

### **Modalit√† 1: Download Automatico** (default)
```python
model = SentenceTransformer('paraphrase-MiniLM-L3-v2')  # 61MB
```

**Pro:**
- ‚úÖ Zero configurazione
- ‚úÖ Funziona out-of-the-box
- ‚úÖ Modello pi√π leggero (61MB vs 90MB)

**Contro:**
- ‚ö†Ô∏è Download al riavvio (~30-60 secondi)
- ‚ö†Ô∏è Usa banda Hugging Face ad ogni riavvio

### **Modalit√† 2: Modello Pre-scaricato** (opzionale, pi√π veloce)
```python
model = SentenceTransformer('./sbert_model')  # Da repository
```

**Pro:**
- ‚úÖ Nessun download (modello gi√† nel repo)
- ‚úÖ Avvio istantaneo
- ‚úÖ Funziona offline (se necessario)

**Contro:**
- ‚ö†Ô∏è Repository pi√π grande (~60MB)
- ‚ö†Ô∏è Richiede setup iniziale (una volta sola)

---

## üöÄ Come Attivare Modalit√† 2 (Opzionale)

Se vuoi evitare il download ad ogni riavvio:

### Passo 1: Scarica il modello localmente

Sul tuo computer:

```bash
cd sbert-app
python download_model.py
```

Questo crea la cartella `sbert_model/` (~60MB)

### Passo 2: Aggiungi al repository GitHub

```bash
# Se il modello √® <100MB (probabile)
git add sbert_model/
git commit -m "Add pre-downloaded SBERT model"
git push

# Se il modello √® >100MB (raro)
# Usa Git LFS: https://git-lfs.github.com/
git lfs install
git lfs track "sbert_model/*"
git add .gitattributes sbert_model/
git commit -m "Add SBERT model with LFS"
git push
```

### Passo 3: Deploy su Streamlit Cloud

L'app rilever√† automaticamente `./sbert_model/` e lo user√†! üéâ

---

## üìä Confronto Modelli

| Modello | Dimensione | Qualit√† | Velocit√† |
|---------|-----------|---------|----------|
| **paraphrase-MiniLM-L3-v2** ‚≠ê | 61 MB | Ottima | Veloce |
| all-MiniLM-L6-v2 | 90 MB | Eccellente | Medio |
| all-mpnet-base-v2 | 420 MB | Massima | Lento |

**Modello attuale:** `paraphrase-MiniLM-L3-v2`
- Perfetto per Streamlit Cloud
- Risultati ~89% accurati (come richiesto)
- Bilanciamento ideale dimensione/qualit√†

---

## üîÑ Alternative a Streamlit Cloud

Se i download ti preoccupano, considera:

### **Hugging Face Spaces** (consigliato se serve storage)
- ‚úÖ Storage persistente (modello scaricato 1 sola volta)
- ‚úÖ Gratis
- ‚úÖ Supporto Docker/Streamlit
- üîó https://huggingface.co/spaces

**Come:**
1. Crea uno Space con Streamlit SDK
2. Carica il codice
3. Il modello viene scaricato una volta e resta in cache

### **Fly.io / Railway** (storage persistente)
- ‚úÖ Storage permanente con volumi
- ‚ö†Ô∏è Piano free limitato
- üîó https://fly.io / https://railway.app

### **Deploy Locale** (nessun limite)
- ‚úÖ Controllo totale
- ‚úÖ Modello sempre disponibile
- ‚ö†Ô∏è Richiede server proprio

---

## üéØ Raccomandazione Finale

**Per il tuo caso d'uso:**

‚úÖ **Usa Streamlit Cloud con Modalit√† 1** (download automatico)

**Perch√©?**
1. La tua app sar√† usata **sporadicamente** (per revisioni/analisi)
2. Download di 60MB ogni tanto √® accettabile
3. Zero configurazione extra
4. I riavvii sono **rari** (~1 volta a settimana)
5. Il caching `@st.cache_resource` mantiene il modello per tutta la sessione

**Il download avviene solo:**
- Primo visitatore dopo un riavvio
- Poi tutti gli altri utenti usano il modello in cache (istantaneo)

---

## ‚è±Ô∏è Timeline Realistica

**Scenario tipico:**

```
Giorno 1, ore 10:00 - Deploy iniziale
  ‚Üí Download modello: 60 secondi
  ‚Üí Utente 1 usa l'app: istantanea
  
Giorno 1, ore 15:00 - Utente 2 visita
  ‚Üí Modello gi√† in cache: istantaneo
  
Giorno 3 - Push aggiornamento codice
  ‚Üí Container riavviato
  ‚Üí Download modello: 60 secondi
  ‚Üí Poi di nuovo istantaneo

Giorno 15 - Nessun riavvio
  ‚Üí Tutto istantaneo
```

**Conclusione:** 60 secondi ogni 7-10 giorni √® accettabile! ‚úÖ

---

## üõ†Ô∏è Se Vuoi Ottimizzare Comunque

Usa la **Modalit√† 2** (modello pre-scaricato):
1. Esegui `python download_model.py`
2. Fai push della cartella `sbert_model/`
3. Avvio sempre istantaneo (0 secondi)

**Trade-off:** Repository +60MB vs 60 secondi di download ogni tanto

---

## üìù Note Tecniche

**Cache di sentence-transformers:**
```
Streamlit Cloud: /tmp/.cache/torch/sentence_transformers/
  ‚Üí Persa ad ogni riavvio ‚ùå

Repository locale: ./sbert_model/
  ‚Üí Persistente nel repo ‚úÖ
```

**RAM Usage:**
- Modello in memoria: ~250MB
- Limite Streamlit Cloud: 1GB
- ‚úÖ Ampio margine disponibile

---

## ‚úÖ Checklist

**Setup Base (Modalit√† 1):**
- [x] Codice aggiornato con modello leggero
- [x] `@st.cache_resource` attivo
- [x] Ready per Streamlit Cloud

**Setup Ottimale (Modalit√† 2):**
- [ ] Eseguito `download_model.py`
- [ ] Cartella `sbert_model/` nel repository
- [ ] Verificato funzionamento locale
- [ ] Push su GitHub completato

---

**Consiglio finale:** Prova prima la Modalit√† 1. Se i 60 secondi di download iniziale ti danno fastidio, passa alla Modalit√† 2 in seguito. üöÄ
